{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification from fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this worked out. Now it's time to create and run a keras model. Since MNIST is getting boring, let's use the fashion MNIST dataset. If you want to learn more on the data set check out the following links\n",
    "\n",
    "[MNIST](https://en.wikipedia.org/wiki/MNIST_database)  \n",
    "[FashionMNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "So in a nutsthell, MNIST contains 60000 28x28 pixel grey scale images of handwritten digits between 0-9 and the corresponding labels. Plus additional 10000 images for testing.\n",
    "\n",
    "Fashing MNIST contains 60000 28x28 pixel grey scale images of fashion articles and the corresponding labels between 0-9. It also contains 10000 test images.\n",
    "\n",
    "Luckyly, this data set is built in to Keras, so let's load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2ece1fab00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "i = 10\n",
    "print(train_labels[i])\n",
    "plt.imshow(train_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we get 60000 images of 28 by 28 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are simply a list of 60000 elements, each one is a number (label) between 0 and 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[9 0 0 ... 3 0 5]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is obviously a shoe :) - Let's normalize the data by making sure every pixel value is between 0..1; this is easy in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
       "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
       "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
       "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
       "        0.34509804, 0.6745098 , 0.25882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
       "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
       "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
       "        0.76862745, 0.89803922, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
       "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
       "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
       "        0.96078431, 0.67843137, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "        0.95294118, 0.79215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
       "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
       "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
       "        0.77254902, 0.81960784, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
       "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
       "        0.46666667, 0.65490196, 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
       "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
       "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
       "        0.81960784, 0.36078431, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
       "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
       "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
       "        1.        , 0.30196078, 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "        0.95686275, 0.62352941, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
       "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
       "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
       "        0.93333333, 0.84313725, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
       "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
       "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
       "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
       "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
       "        0.90980392, 0.96470588, 0.        ],\n",
       "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
       "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
       "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
       "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
       "        0.89411765, 0.88235294, 0.        ],\n",
       "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
       "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
       "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
       "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
       "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
       "        0.87843137, 0.89803922, 0.11372549],\n",
       "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "        0.86666667, 0.90196078, 0.2627451 ],\n",
       "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
       "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
       "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
       "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
       "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
       "        0.80392157, 0.80784314, 0.45098039],\n",
       "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
       "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
       "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
       "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
       "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
       "        0.69411765, 0.82352941, 0.36078431],\n",
       "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
       "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
       "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
       "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
       "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
       "        0.84705882, 0.66666667, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
       "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
       "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
       "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
       "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "train_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to write our **hello world** softmax regression model, the following code does the job. If you are familiar with Keras, this is really basic stuff. There is only one catch. The following code doesn't run since the latest stable Keras version is incompatible with the alpha release of TensorFlow 2.0. So the following code is for illustration purposes only. Don't run it, it will destroy your hard drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.activations import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4976 - accuracy: 0.8241 - val_loss: 0.4204 - val_accuracy: 0.8501\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3772 - accuracy: 0.8634 - val_loss: 0.3844 - val_accuracy: 0.8591\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3380 - accuracy: 0.8767 - val_loss: 0.3871 - val_accuracy: 0.8560\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3134 - accuracy: 0.8858 - val_loss: 0.3562 - val_accuracy: 0.8708\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2948 - accuracy: 0.8908 - val_loss: 0.3701 - val_accuracy: 0.8681\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2798 - accuracy: 0.8965 - val_loss: 0.3524 - val_accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2679 - accuracy: 0.9007 - val_loss: 0.3514 - val_accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2604 - accuracy: 0.9035 - val_loss: 0.3578 - val_accuracy: 0.8693\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2476 - accuracy: 0.9070 - val_loss: 0.3480 - val_accuracy: 0.8777\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2387 - accuracy: 0.9107 - val_loss: 0.3470 - val_accuracy: 0.8793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2ecf44a710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation=relu),\n",
    "    Dense(10, activation=softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 836us/step - loss: 0.3470 - accuracy: 0.8793\n",
      "Test loss:  0.3469761610031128\n",
      "Test accuracy:  0.8792999982833862\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels)\n",
    "print(\"Test loss: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we didn't change the Keras code at all, but now all imports are coming from the tensorflow package. I felt a bit bad when I've noticed that TensorFlow has eaten up Keras, but in reality, nobody uses a Keras runtime other then TensorFlow anyway, so it doesn't really matter. Just be aware that Keras is Google now and part of TensorFlow. In the next notebook, we'll cover the stategies for parallel training. So stay tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 54s 116ms/step - loss: 0.5122 - accuracy: 0.8172 - val_loss: 0.3263 - val_accuracy: 0.8795\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 57s 122ms/step - loss: 0.3332 - accuracy: 0.8810 - val_loss: 0.2801 - val_accuracy: 0.8977\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 57s 123ms/step - loss: 0.2822 - accuracy: 0.8988 - val_loss: 0.2524 - val_accuracy: 0.9068\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.2522 - accuracy: 0.9087 - val_loss: 0.2396 - val_accuracy: 0.9086\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 59s 125ms/step - loss: 0.2284 - accuracy: 0.9167 - val_loss: 0.2259 - val_accuracy: 0.9162\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 58s 123ms/step - loss: 0.2129 - accuracy: 0.9216 - val_loss: 0.2219 - val_accuracy: 0.9181\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 60s 127ms/step - loss: 0.1959 - accuracy: 0.9278 - val_loss: 0.2164 - val_accuracy: 0.9224\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 57s 122ms/step - loss: 0.1832 - accuracy: 0.9322 - val_loss: 0.2171 - val_accuracy: 0.9214\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 60s 128ms/step - loss: 0.1691 - accuracy: 0.9365 - val_loss: 0.2147 - val_accuracy: 0.9267\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 57s 121ms/step - loss: 0.1594 - accuracy: 0.9401 - val_loss: 0.2133 - val_accuracy: 0.9264\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 58s 125ms/step - loss: 0.1486 - accuracy: 0.9441 - val_loss: 0.2157 - val_accuracy: 0.9265\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 59s 126ms/step - loss: 0.1432 - accuracy: 0.9455 - val_loss: 0.2116 - val_accuracy: 0.9277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2eb0117048>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train = train_images\n",
    "x_test = test_images\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "        #      optimizer=keras.optimizers.Adadelta(),\n",
    "     #         metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save full model (architecture + weights)\n",
    "model.save(\"model_fashion_mnist.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
